<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Distributed Classes · HealpixMPI.jl</title><meta name="title" content="Distributed Classes · HealpixMPI.jl"/><meta property="og:title" content="Distributed Classes · HealpixMPI.jl"/><meta property="twitter:title" content="Distributed Classes · HealpixMPI.jl"/><meta name="description" content="Documentation for HealpixMPI.jl."/><meta property="og:description" content="Documentation for HealpixMPI.jl."/><meta property="twitter:description" content="Documentation for HealpixMPI.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="HealpixMPI.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">HealpixMPI.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>Distributed Classes</a><ul class="internal"><li><a class="tocitem" href="#Initializing-a-distributed-type"><span>Initializing a distributed type</span></a></li><li><a class="tocitem" href="#Gathering-data"><span>Gathering data</span></a></li><li><a class="tocitem" href="#Distributing-Strategy"><span>Distributing Strategy</span></a></li><li><a class="tocitem" href="#Map-specific-functions"><span>Map-specific functions</span></a></li><li><a class="tocitem" href="#Alm-specific-functions"><span>Alm-specific functions</span></a></li></ul></li><li><a class="tocitem" href="../sht/">Spherical Harmonics</a></li><li><a class="tocitem" href="../misc/">Miscellanea</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Distributed Classes</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Distributed Classes</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/LeeoBianchi/HealpixMPI.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/main/docs/src/distribute.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Distributed-Classes"><a class="docs-heading-anchor" href="#Distributed-Classes">Distributed Classes</a><a id="Distributed-Classes-1"></a><a class="docs-heading-anchor-permalink" href="#Distributed-Classes" title="Permalink"></a></h1><p>As mentioned in the introduction, HealpixMPI has the main purpose of providing an MPI parallelization of the main functionalities of <a href="https://github.com/ziotom78/Healpix.jl">Healpix.jl</a>, distributing maps and harmonic coefficients over the MPI tasks efficiently. This is made possible by the implementation of two data types: <a href="#HealpixMPI.DMap"><code>DMap</code></a> and <a href="#HealpixMPI.DAlm"><code>DAlm</code></a>, mirroring <a href="https://ziotom78.github.io/Healpix.jl/stable/mapfunc/#Healpix.HealpixMap"><code>HealpixMap</code></a> and <a href="https://ziotom78.github.io/Healpix.jl/stable/alm/#Healpix.Alm"><code>Alm</code></a> types of Healpix.jl respectively, and containing a well-defined subset of a map or harmonic coefficients, to be constructed on each MPI task.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.AbstractDMap" href="#HealpixMPI.AbstractDMap"><code>HealpixMPI.AbstractDMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractDMap</code></pre><p>Abstract type to allow multiple dispatch.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L48-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.DMap" href="#HealpixMPI.DMap"><code>HealpixMPI.DMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct DMap{S&lt;:Strategy, T&lt;:Real, N} &lt;: AbstractDMap</code></pre><p>A subset of a Healpix map, containing only certain rings (as specified in the <code>info</code> field). The type <code>T</code> is used for the value of the pixels in a map, it must be a <code>Real</code> (usually float). The signature field <code>N</code> represents the number of components in the <code>DMap</code> object, it can only be <code>1</code> for a spin-0 field and <code>2</code> otherwise.</p><p>A <code>DMap</code> type contains the following fields:</p><ul><li><code>pixels::Matrix{T}</code>: array of pixels composing the subset, dimensions are <code>(npixels, ncomp)</code>.</li><li><code>info::GeomInfo</code>: a <code>GeomInfo</code> object describing the HealpixMap subset.</li></ul><p>The <code>GeomInfoMPI</code> contained in <code>info</code> must match exactly the characteristic of the Map subset, this is already automatically constructed when <a href="#MPI.Scatter!"><code>MPI.Scatter!</code></a> is called, reason why this method for initializing a <code>DMap</code> is reccomended.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L55-L72">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.AbstractDAlm" href="#HealpixMPI.AbstractDAlm"><code>HealpixMPI.AbstractDAlm</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Abstract type to allow multiple dispatch.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L51-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.DAlm" href="#HealpixMPI.DAlm"><code>HealpixMPI.DAlm</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct DAlm{S&lt;:Strategy, T&lt;:Number}</code></pre><p>An MPI-distributed subset of harmonic coefficients a_ℓm, referring only to certain values of m.</p><p>The type <code>T</code> is used for the value of each harmonic coefficient, and it must be a <code>Number</code> (one should however only use complex types for this).</p><p>A <code>SubAlm</code> type contains the following fields:</p><ul><li><code>alm::Matrix{T}</code>: the array of harmonic coefficients, of dimensions <code>(nalm, ncomp)</code>.</li><li><code>info::AlmInfoMPI{I}</code>: an <code>AlmInfo</code> object describing the alm subset.</li></ul><p><code>ncomp</code> can be greater than one for supporting polarized shts. The <code>AlmInfo</code> contained in <code>info</code> must match exactly the characteristic of the Alm subset, this can be constructed through the function <code>make_general_alm_info</code>, for instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L56-L74">source</a></section></article><p>An instance of <code>DMap</code> (or <code>DAlm</code>) embeds, whithin the field <code>info</code>, a <a href="#HealpixMPI.GeomInfoMPI"><code>GeomInfoMPI</code></a> (or <a href="#HealpixMPI.AlmInfoMPI"><code>AlmInfoMPI</code></a>) object. These latter, in turn, contain all the necessairy information about:</p><ul><li>The whole map geometry (or the whole set of harmonic coefficients).</li><li>The composition of the <em>local</em> subset.</li><li>the MPI communicator.</li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.GeomInfoMPI" href="#HealpixMPI.GeomInfoMPI"><code>HealpixMPI.GeomInfoMPI</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct GeomInfoMPI</code></pre><p>Information describing an MPI-distributed subset of a <code>HealpixMap</code>, contained in a <code>DMap</code>.</p><p>A <code>GeomInfoMPI</code> type contains:</p><ul><li><code>comm</code>: MPI communicator used.</li><li><code>nside</code>: NSIDE parameter of the whole map.</li><li><code>maxnr</code>: maximum number of rings in the subsets, over the tasks involved.</li><li><code>thetatot</code>: array of the colatitudes of the whole map ordered by task first and RR within each task</li><li><code>rings</code>: array of the ring indexes (w.r.t. the whole map) contained in the subset.</li><li><code>rstart</code>: array containing the 1-based index of the first pixel of each ring contained in the subset.</li><li><code>nphi</code>: array containing the number of pixels in every ring contained in the subset.</li><li><code>theta</code>: array of colatitudes (in radians) of the rings contained in the subset.</li><li><code>phi0</code>: array containing the values of the azimuth (in radians) of the first pixel in every ring.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L2-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.AlmInfoMPI" href="#HealpixMPI.AlmInfoMPI"><code>HealpixMPI.AlmInfoMPI</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct AlmInfoMPI</code></pre><p>Information describing an MPI-distributed subset of <code>Alm</code>, contained in a <code>DAlm</code>.</p><p>An <code>AlmInfoMPI</code> type contains:</p><ul><li><code>comm</code>: MPI communicator used.</li><li><code>lmax</code>: the maximum value of <span>$ℓ$</span>.</li><li><code>mmax</code>: the maximum value of <span>$m$</span> on the whole <code>Alm</code> set.</li><li><code>maxnm</code>: maximum value (over tasks) of nm (number of m values).</li><li><code>mval</code>: array of values of <span>$m$</span> contained in the subset.</li><li><code>mstart</code>: array hypothetical indexes of the harmonic coefficient with ℓ=0, m. #FIXME: for now 0-based</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L16-L29">source</a></section></article><h2 id="Initializing-a-distributed-type"><a class="docs-heading-anchor" href="#Initializing-a-distributed-type">Initializing a distributed type</a><a id="Initializing-a-distributed-type-1"></a><a class="docs-heading-anchor-permalink" href="#Initializing-a-distributed-type" title="Permalink"></a></h2><p>The recommended way to construct a local subset of a map or harmonic coefficients, is to start with an instance of <code>HealpixMap</code> (in <code>RingOrder</code>) or <code>Alm</code> on the root task, and call one of the apposite overloads of the standard <code>MPI.Scatter!</code> function, provided by HealpixMPI.jl. Such function would in fact save the user the job of constructing all the required ancillary information describing the data subset, doing so through efficient and tested methods.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPI.Scatter!" href="#MPI.Scatter!"><code>MPI.Scatter!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">Scatter!(in_alm::Union{Healpix.Alm{T,Array{T,1}}, AbstractArray{Healpix.Alm{T,Array{T,1}},1}}, out_d_alm::DAlm{T}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Scatter!(in_alm::AbstractArray{Healpix.Alm{T,Array{T,1}},1}, out_d_alm::DAlm{T}, out_d_pol_alm::DAlm{T}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Scatter!(::Nothing, out_d_alm::DAlm{T}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Scatter!(::Nothing, out_d_alm::DAlm{T}, out_d_pol_alm::DAlm{T}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Scatter!(in_alm, out_d_alm::DAlm{S,T}, comm::MPI.Comm; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Scatter!(in_alm, out_d_alm::DAlm{S,T}, out_d_alm::DAlm{S,T}, comm::MPI.Comm; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}</code></pre><p>Distributes the <code>Alm</code> object passed in input on the <code>root</code> task overwriting the <code>DAlm</code> objects passed on each task, according to the specified strategy.</p><p>As in the standard MPI function, the <code>in_alm</code> in input can be <code>nothing</code> on non-root tasks, since it will be ignored anyway.</p><p>To distribute a set of Alms representing a POLARIZED field there are 2 options:</p><ul><li>Pass in input a <code>AbstractArray{Healpix.Alm{T,Array{T,1}},1}</code> with only E and B components and one output <code>DAlm</code> object which will contain both.</li><li>Pass in input a <code>AbstractArray{Healpix.Alm{T,Array{T,1}},1}</code> with T, E and B components and two output <code>DAlm</code> objects which will contain T and E &amp; B respectively.</li></ul><p>This is so that the resulting <code>DAlm</code> objects can be directly passed to the sht functions which only accept in input the intensity component for a scalar transform and two polarization components for a spinned transform.</p><p>If the keyword <code>clear</code> is set to <code>true</code> it frees the memory of each task from the (potentially big) <code>Alm</code> object.</p><p><strong>Arguments:</strong></p><ul><li><code>in_alm::Alm{T,Array{T,1}}</code>: <code>Alm</code> object to distribute over the MPI tasks.</li><li><code>out_d_alm::DAlm{T}</code>: output <code>DAlm</code> object.</li></ul><p><strong>Keywords:</strong></p><ul><li><code>root::Integer</code>: rank of the task to be considered as &quot;root&quot;, it is 0 by default.</li><li><code>clear::Bool</code>: if true deletes the input <code>Alm</code> after having performed the &quot;scattering&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L190-L218">source</a></section><section><div><pre><code class="language-julia hljs">Scatter!(in_map::Union{Healpix.HealpixMap{T1, Healpix.RingOrder}, Healpix.PolarizedHealpixMap{T1, Healpix.RingOrder}}, out_d_map::DMap{S,T2,I}; root::Integer = 0, clear::Bool = false) where {T1&lt;:Real, T2&lt;:Real, S&lt;:Strategy}
Scatter!(in_map::Healpix.PolarizedHealpixMap{T1, Healpix.RingOrder}, out_d_map::DMap{S,T2}, out_d_pol_map::DMap{S,T2}; root::Integer = 0, clear::Bool = false) where {T1&lt;:Real, T2&lt;:Real, S&lt;:Strategy}
Scatter!(in_map::Nothing, out_d_map::DMap{S,T}; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Scatter!(in_map::Nothing, out_d_map::DMap{S,T}, out_d_pol_map::DMap{S,T}; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Scatter!(in_map, out_d_map::DMap{S,T}, comm::MPI.Comm; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Scatter!(in_map, out_d_map::DMap{S,T}, out_d_pol_map::DMap{S,T}, comm::MPI.Comm; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}</code></pre><p>Distributes the <code>HealpixMap</code> object passed in input on the <code>root</code> task overwriting the <code>DMap</code> objects passed on each task, according to the specified strategy.</p><p>There are two options to distribute a <code>HealpixMap</code> which represents a polarized field:</p><ul><li>To pass an input <code>PolarizedHealpixMap</code> object and only one output <code>DMap</code> object, in this case the latter will be exclusively filled with its <code>q</code> and <code>u</code> components.</li><li>To pass an input <code>PolarizedHealpixMap</code> object and two output <code>DMap</code> object, in this case one will contain the <code>i</code> map, while the second <code>q</code> and <code>u</code>.</li></ul><p>This is so that the resulting <code>DMap</code> objects can be directly passed to the sht functions which only accept in input the intensity component for a scalar transform and two polarization components for a spinned transform.</p><p>As in the standard MPI function, the <code>in_map</code> in input can be <code>nothing</code> on non-root tasks, since it will be ignored anyway.</p><p>If the keyword <code>clear</code> is set to <code>true</code> it frees the memory of each task from the (potentially bulky) <code>HealpixMap</code> object.</p><p><strong>Arguments:</strong></p><ul><li><code>in_map:</code>HealpixMap<code>or</code>PolarizedHealpixMap` object to distribute over the MPI tasks.</li><li><code>out_d_map::DMap{S,T}</code>: output <code>DMap</code> object.</li></ul><p><strong>Keywords:</strong></p><ul><li><code>root::Integer</code>: rank of the task to be considered as &quot;root&quot;, it is 0 by default.</li><li><code>clear::Bool</code>: if true deletes the input map after having performed the &quot;scattering&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L216-L244">source</a></section></article><p>While distributing a set of harmonic coefficients means that each MPI task will host a <code>DAlm</code> object containing only the coefficients corresponding to some specific values of m, the distribution of a map is performed by rings. Each MPI task will then host a <code>DMap</code> object containing only the pixels composing some specified rings of the entire <code>HealpixMap</code>. Note that, for spherical harmonic transforms efficiency, it is recommended to assign pairs of rings with same latitude (i.e. symmetric w.r.t. the equator) to the same task, in order to preserve the geometric symmetry of the map.</p><p>The following example shows the standard way to initialize a <code>DAlm</code> object through a round robin strategy (see the paragraph <code>Distributing Strategy</code> for more details about this). #<a href="https://leeobianchi.github.io/HealpixMPI.jl/dev/distribute/#Distributing-Strategy"><code>Distributing Strategy</code></a></p><pre><code class="language-julia hljs">using HealpixMPI

MPI.Init()
comm = MPI.COMM_WORLD

alm = Alm(5, 5, randn(ComplexF64, numberOfAlms(5))) #inizialize random Healpix Alm
d_alm = DAlm{RR}() #inizialize empty DAlm to be filled according to RR strategy

MPI.Scatter!(alm, d_alm, comm) #fill d_alm</code></pre><h2 id="Gathering-data"><a class="docs-heading-anchor" href="#Gathering-data">Gathering data</a><a id="Gathering-data-1"></a><a class="docs-heading-anchor-permalink" href="#Gathering-data" title="Permalink"></a></h2><p>Analogously to <code>MPI.Scatter!</code>, HealpixMPI.jl also provides overloads of <code>MPI.Gather!</code> (and <code>MPI.Allgather!</code>). These latter allow to re-group subsets of map or alm into a <code>HealpixMap</code> or <code>Alm</code> only on the root task (or on every MPI task involved).</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPI.Gather!" href="#MPI.Gather!"><code>MPI.Gather!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">Gather!(in_d_alm::DAlm{S,T}, out_alm::Union{Healpix.Alm{T,Array{T,1}}, Nothing}, comp::Integer; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Gather!(in_d_alm::DAlm{S,T}, out_alm::Healpix.Alm{T,Array{T,1}}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Gather!(in_d_alm::DAlm{S,T}, out_alm::AbstractArray{Healpix.Alm{T,Array{T,1}},1}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Gather!(in_d_alm::DAlm{S,T}, out_alm::Nothing; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Gather!(in_d_alm::DAlm{S,T}, in_d_pol_alm::DAlm{S,T}, out_alm::AbstractArray{Healpix.Alm{T,Array{T,1}},1}; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Gather!(in_d_alm::DAlm{S,T}, in_d_pol_alm::DAlm{S,T}, out_alm::Nothing; root::Integer = 0, clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}</code></pre><p>Gathers the <code>DAlm</code> objects passed on each task overwriting the <code>Alm</code> object passed in input on the <code>root</code> task according to the specified <code>strategy</code> (by default <code>:RR</code> for Round Robin). Note that the strategy must match the one used to &quot;scatter&quot; the a_lm.</p><p>As in the standard MPI function, the <code>out_alm</code> can be <code>nothing</code> on non-root tasks, since it will be ignored anyway.</p><p>Note: for a polarized field, if two input <code>DAlm</code> objects are passed, they are expected to contain the T and E &amp; B components respectively and the output will be an array of three <code>Alm</code> objects which can be passed to <code>Healpix.jl</code> functions directly.</p><p>If the keyword <code>clear</code> is set to <code>true</code> it frees the memory of each task from the (potentially bulky) <code>DAlm</code> object.</p><p><strong>Arguments:</strong></p><ul><li><code>in_d_alm::DAlm{T}</code>: <code>DAlm</code> object to gather from the MPI tasks.</li><li><code>out_d_alm::Alm{T,Array{T,1}}</code>: output <code>Alm</code> object.</li></ul><p><strong>Keywords:</strong></p><ul><li><code>strategy::Symbol</code>: Strategy to be used, by default <code>:RR</code> for &quot;Round Robin&quot;.</li><li><code>root::Integer</code>: rank of the task to be considered as &quot;root&quot;, it is 0 by default.</li><li><code>clear::Bool</code>: if true deletes the input <code>Alm</code> after having performed the &quot;scattering&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L379-L410">source</a></section><section><div><pre><code class="language-julia hljs">Gather!(in_d_map::DMap{S,T}, out_map::Union{Healpix.HealpixMap{T,Healpix.RingOrder}, Nothing}, comp::Integer; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Gather!(in_d_map::DMap{S,T}, out_map; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Gather!(in_d_map::DMap{S,T}, in_d_pol_map::DMap{S,T}, out_map::Healpix.PolarizedHealpixMap{T,Healpix.RingOrder}; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Gather!(in_d_map::DMap{S,T}, in_d_pol_map::DMap{S,T}, out_map::Nothing; root::Integer = 0, clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}</code></pre><p>Gathers the <code>DMap</code> objects passed on each task overwriting the <code>HealpixMap</code> or <code>PolarizedHealpixMap</code> object passed in input on the <code>root</code> task according to the specified <code>Strategy</code>.</p><p>Similarly to the standard MPI function, the <code>out_map</code> can be <code>nothing</code> on non-root tasks, since it will be ignored anyway.</p><p>If the keyword <code>clear</code> is set to <code>true</code> it frees the memory of each task from the (potentially bulky) <code>DMap</code> object.</p><p><strong>Arguments:</strong></p><ul><li><code>in_d_map::DMap{S,T}</code>: <code>DMap</code> object to gather from the MPI tasks.</li><li><code>out_map</code>: output <code>HealpixMap</code> or <code>PolarizedHealpixMap</code> object.</li></ul><p><strong>Optional:</strong></p><ul><li><code>comp::Integer</code>: Specify which component (column) from the pixel matrix in <code>DMap</code> is to be gathered, defaulted to 1.</li></ul><p><strong>Keywords:</strong></p><ul><li><code>root::Integer</code>: rank of the task to be considered as &quot;root&quot;, it is 0 by default.</li><li><code>clear::Bool</code>: if true deletes the input <code>DMap</code> after having performed the &quot;scattering&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L403-L428">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPI.Allgather!" href="#MPI.Allgather!"><code>MPI.Allgather!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">Allgather!(in_d_alm::DAlm{S,T}, out_alm::Healpix.Alm{T,Array{T,1}}, comp::Integer; clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Allgather!(in_d_alm::DAlm{S,T}, out_alm::Healpix.Alm{T,Array{T,1}}; clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Allgather!(in_d_alm::DAlm{S,T}, out_alm::AbstractArray{Healpix.Alm{T,Array{T,1}},1}; clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}
Allgather!(in_d_alm::DAlm{S,T}, in_d_pol_alm::DAlm{S,T}, out_alm::AbstractArray{Healpix.Alm{T,Array{T,1}},1}; clear::Bool = false) where {S&lt;:Strategy, T&lt;:Number}</code></pre><p>Gathers the <code>DAlm</code> objects passed on each task overwriting the <code>Alm</code> object passed in input on the <code>root</code> task according to the specified <code>strategy</code> (by default <code>:RR</code> for Round Robin). Note that the strategy must match the one used to &quot;scatter&quot; the a_lm.</p><p>As in the standard MPI function, the <code>out_alm</code> can be <code>nothing</code> on non-root tasks, since it will be ignored anyway.</p><p>If the keyword <code>clear</code> is set to <code>true</code> it frees the memory of each task from the (potentially bulky) <code>DAlm</code> object.</p><p><strong>Arguments:</strong></p><ul><li><code>in_d_alm::DAlm{T}</code>: <code>DAlm</code> object to gather from the MPI tasks.</li><li><code>out_d_alm::Alm{T,Array{T,1}}</code>: output <code>Alm</code> object.</li></ul><p><strong>Keywords:</strong></p><ul><li><code>strategy::Symbol</code>: Strategy to be used, by default <code>:RR</code> for &quot;Round Robin&quot;.</li><li><code>clear::Bool</code>: if true deletes the input <code>Alm</code> after having performed the &quot;scattering&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L525-L549">source</a></section><section><div><pre><code class="language-julia hljs">Allgather!(in_d_map::DMap{S,T}, out_map::Healpix.HealpixMap{T,Healpix.RingOrder} comp::Integer; clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Allgather!(in_d_map::DMap{S,T}, out_map::Healpix.HealpixMap{T,Healpix.RingOrder}; clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}
Allgather!(in_d_map::DMap{S,T}, out_map::Healpix.PolarizedHealpixMap{T,Healpix.RingOrder}; clear::Bool = false) where {T&lt;:Real, S&lt;:Strategy}</code></pre><p>Gathers the <code>DMap</code> objects passed on each task overwriting the <code>out_map</code> object passed in input on EVERY task according to the specified <code>strategy</code> (by default <code>:RR</code> for Round Robin). Note that the strategy must match the one used to &quot;scatter&quot; the map.</p><p>If the keyword <code>clear</code> is set to <code>true</code> it frees the memory of each task from the (potentially bulky) <code>DMap</code> object.</p><p><strong>Arguments:</strong></p><ul><li><code>in_d_map::DMap{S,T}</code>: <code>DMap</code> object to gather from the MPI tasks.</li><li><code>out_d_map</code>: output <code>HealpixMap</code> or <code>PolarizedHealpixMap</code> object to overwrite.</li></ul><p><strong>Optional:</strong></p><ul><li><code>comp::Integer</code>: Specify which component (column) from the pixel matrix in <code>DMap</code> is to be gathered, defaulted to 1.</li></ul><p><strong>Keywords:</strong></p><ul><li><code>clear::Bool</code>: if true deletes the input <code>Alm</code> after having performed the &quot;scattering&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L508-L530">source</a></section></article><h2 id="Distributing-Strategy"><a class="docs-heading-anchor" href="#Distributing-Strategy">Distributing Strategy</a><a id="Distributing-Strategy-1"></a><a class="docs-heading-anchor-permalink" href="#Distributing-Strategy" title="Permalink"></a></h2><p>It is also worth mentioning that one could find many different strategies to distribute a set of data over multiple MPI tasks. So far, the only one implemented in HealpixMPI.jl, which should guarantee an adequate work balance between tasks, is the so-called &quot;round robin&quot; strategy: assuming <span>$N$</span> MPI tasks, the map is distributed such that task <span>$i$</span> hosts the map rings <span>$i$</span>, <span>$i + N$</span>, <span>$i + 2N$</span>, etc. (and their counterparts on the other hemisphere). Similarly, for the spherical harmonic coefficients, task <span>$i$</span> would hold all coefficients for <span>$m = i$</span>, <span>$i + N$</span>, <span>$i + 2 N$</span>, etc.</p><p>The strategy is intrinsically specified in a <code>DMap</code> or <code>DAlm</code> instance through an abstract type (e.g. <code>RR</code>), inherited from a super-type <code>Strategy</code>; in the same way as the pixel ordering is specified in a <code>HealpixMap</code> in Healpix.jl.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.Strategy" href="#HealpixMPI.Strategy"><code>HealpixMPI.Strategy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type Strategy</code></pre><p>Abstract type representing the strategy used to distribute a Healpix map or alm. If the user wishes to implement it&#39;s own, it should be added as an inherited type, see <code>RR</code> as an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/strategy.jl#L1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.RR" href="#HealpixMPI.RR"><code>HealpixMPI.RR</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type RR &lt;: Strategy</code></pre><p>The <code>RR</code> type should be used when creating a &quot;Distributed&quot; type in order to specify that the data has been distributed according to &quot;Round Robin&quot;.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/strategy.jl#L10-L15">source</a></section></article><p>This kind of solution allows for two great features:</p><ul><li><p>An efficient and fast multiple-dispatch, allowing a function to recognize the distribution strategy used on data structure without the usage of any <code>if</code> statement.</p></li><li><p>Allows to add other distributing strategies if needed for future developments by simply adding an inherited type in the source file <code>strategy.jl</code> with a single line of code:</p></li></ul><pre><code class="language-julia hljs">abstract type NewStrat&lt;:Strategy end</code></pre><h2 id="Map-specific-functions"><a class="docs-heading-anchor" href="#Map-specific-functions">Map-specific functions</a><a id="Map-specific-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Map-specific-functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.get_nrings_RR" href="#HealpixMPI.get_nrings_RR"><code>HealpixMPI.get_nrings_RR</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_nrings_RR(eq_idx::Integer, task_rank::Integer, c_size::Integer)
get_nrings_RR(res::Resolution, task_rank::Integer, c_size::Integer)</code></pre><p>Return number of rings on specified task given total map resolution and communicator size according to Round Robin.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L92-L98">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.get_rindexes_RR" href="#HealpixMPI.get_rindexes_RR"><code>HealpixMPI.get_rindexes_RR</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_rindexes_RR(local_nrings::Integer, eq_idx::Integer, t_rank::Integer, c_size::Integer)
get_rindexes_RR(nside::Integer, t_rank::Integer, c_size::Integer)</code></pre><p>Return array of rings on specified task (0-base index) given total map resolution and communicator size, ordered from the equator to the poles alternating N/S, according to Round Robin.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L105-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.get_rindexes_tot_RR" href="#HealpixMPI.get_rindexes_tot_RR"><code>HealpixMPI.get_rindexes_tot_RR</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_rindexes_tot_RR(eq_index::Integer, c_size::Integer)</code></pre><p>Return array of ring indexes ordered by task first and RR within each task.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/map.jl#L129-L133">source</a></section></article><h2 id="Alm-specific-functions"><a class="docs-heading-anchor" href="#Alm-specific-functions">Alm-specific functions</a><a id="Alm-specific-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Alm-specific-functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.get_nm_RR" href="#HealpixMPI.get_nm_RR"><code>HealpixMPI.get_nm_RR</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_nm_RR(global_mmax::Integer, task_rank::Integer, c_size::Integer)</code></pre><p>Return number of m&#39;s on specified task in a Round Robin strategy</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L97-L101">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.get_mval_RR" href="#HealpixMPI.get_mval_RR"><code>HealpixMPI.get_mval_RR</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_mval_RR(global_mmax::Integer, task_rank::Integer, c_size::Integer)</code></pre><p>Return array of m values on specified task in a Round Robin strategy</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L107-L111">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.get_m_tasks_RR" href="#HealpixMPI.get_m_tasks_RR"><code>HealpixMPI.get_m_tasks_RR</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_m_tasks_RR(mmax::Integer, c_size::Integer)</code></pre><p>Computes an array containing the task each m in the full range [0, <code>mmax</code>] is assigned to according to a Round Robin strategy, given the communicator size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L121-L126">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HealpixMPI.make_mstart_complex" href="#HealpixMPI.make_mstart_complex"><code>HealpixMPI.make_mstart_complex</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">make_mstart_complex(lmax::Integer, stride::Integer, mval::AbstractArray{T}) where T &lt;: Integer</code></pre><p>Computes the 1-based <code>mstart</code> array given any <code>mval</code> and <code>lmax</code> for <code>Alm</code> in complex representation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/LeeoBianchi/HealpixMPI.jl/blob/037bf450efc5332bd28355b61a7212d75c74f902/src/alm.jl#L135-L140">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Introduction</a><a class="docs-footer-nextpage" href="../sht/">Spherical Harmonics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 20 May 2024 13:24">Monday 20 May 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
